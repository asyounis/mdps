experiment_templates:


  - MDPS_Training_Filters_Base_Template:


      # The parameters for the device to use
      # This specifies which GPU or how many GPUs we want and also what the requirements are for the GPU
      device_configs:
        device: "cuda_use_all"
        min_free_memory_gb: 1.0
        max_number_of_tasks: 10

      # Specify the configs needed for training
      training_configs:       

        # The configs that specify early stopping
        early_stopping_configs:
          patience: 10
          start_offset: 25
          min_delta: 0
          max_lr_change: 3


        # The configs for the loss.  At minimum you need to specify the "name". 
        # All additional configs are metric specific
        loss_configs: 
          name: CombinedMetric

          metric_configs:
            - metric_forward:
                name: KDENLLMetric
                alpha: 0.5
                output_keys:
                  particles: "forward_particles"
                  particle_weights: "forward_particle_weights"
                  bandwidths: "forward_bandwidths"

                particle_extract_dim_params:
                  0: 
                    dim_in_kde: 0
                    kde_distribution_type: "Normal"
                  1: 
                    dim_in_kde: 1
                    kde_distribution_type: "Normal"
                  2: 
                    dim_in_kde: 2
                    kde_distribution_type: "VonMises"

            - metric_backward:
                name: KDENLLMetric
                alpha: 0.5
                output_keys:
                  particles: "backward_particles"
                  particle_weights: "backward_particle_weights"
                  bandwidths: "backward_bandwidths"

                particle_extract_dim_params:
                  0: 
                    dim_in_kde: 0
                    kde_distribution_type: "Normal"
                  1: 
                    dim_in_kde: 1
                    kde_distribution_type: "Normal"
                  2: 
                    dim_in_kde: 2
                    kde_distribution_type: "VonMises"




  - MDPS_Training_Filters_Stage_1_Template:
    
      # The config file for the dataset we want to use 
      dataset_configs_file: "../experiments/kitti/shared_configs/dataset_kitti_sequences_short.yaml"

      # Specify which model to load
      # We want to load from the mapillary saved files
      pretrained_models:
        full_model: <mapillary_root_save_dir>/004_training_all/<framework_var_run_number>/models/best/full_model.pt


      # The save dir
      save_dir: <root_save_dir>/001_training_filters_stage_1/

      # Specify the configs needed for training
      training_configs:       


        # The batch sizes for training per GPU
        # This will automatically scale the batch size when we scale the number of GPUs
        batch_sizes_per_gpu:
          training: 3
          validation: 3

        # These are the learning rates for the internal models
        # If you want to use 1 learnung rate for all the models you can set "full_model" but then there can be no other entries
        learning_rates:
          forward_output_bandwidth_model:       "freeze"
          backward_output_bandwidth_model:      "freeze"
          output_bandwidth_model:               "freeze"
          output_weights_model:                 "freeze"

          forward_resampling_bandwidth_model:   0.00001
          backward_resampling_bandwidth_model:  0.00001
          
          forward_dynamics_model:               0.001
          backward_dynamics_model:              0.001
          forward_output_weights_model:         0.001
          backward_output_weights_model:        0.001
          forward_resampling_weights_model:     0.001
          backward_resampling_weights_model:    0.001
          
          map_encoder_model:                    0.001
          observation_encoder_model:            0.001




  - MDPS_Training_Filters_Stage_2_Template:
    
      # The save dir
      save_dir: <root_save_dir>/002_training_filters_stage_2/

      # The config file for the dataset we want to use 
      dataset_configs_file: "../experiments/kitti/shared_configs/dataset_kitti_sequences_long.yaml"

      # Specify which model to load
      pretrained_models:
        full_model: <root_save_dir>/001_training_filters_stage_1/<framework_var_run_number>/models/best/full_model.pt

      # Specify the configs needed for training
      training_configs:       


        # The batch sizes for training per GPU
        # This will automatically scale the batch size when we scale the number of GPUs
        batch_sizes_per_gpu:
          training: 2
          validation: 2

        # # How many epochs to train for
        # epochs: 5

        # These are the learning rates for the internal models
        # If you want to use 1 learnung rate for all the models you can set "full_model" but then there can be no other entries
        learning_rates:
          forward_output_bandwidth_model:       "freeze"
          backward_output_bandwidth_model:      "freeze"
          output_bandwidth_model:               "freeze"
          output_weights_model:                 "freeze"

          forward_resampling_bandwidth_model:   0.000001
          backward_resampling_bandwidth_model:  0.000001
          
          forward_dynamics_model:               0.0001
          backward_dynamics_model:              0.0001
          forward_output_weights_model:         0.0001
          backward_output_weights_model:        0.0001
          forward_resampling_weights_model:     0.0001
          backward_resampling_weights_model:    0.0001
          
          map_encoder_model:                    "Freeze"
          observation_encoder_model:            "Freeze"

        models_with_disabled_gradients:
          - observation_encoder_model
          - map_encoder_model



  - MDPS_Training_Filters_Stage_3_Template:
    
      # The save dir
      save_dir: <root_save_dir>/003_training_filters_stage_3/

      # The config file for the dataset we want to use 
      dataset_configs_file: "../experiments/kitti/shared_configs/dataset_kitti_sequences_long.yaml"

      # Specify which model to load
      pretrained_models:
        full_model: <root_save_dir>/002_training_filters_stage_2/<framework_var_run_number>/models/best/full_model.pt

      # Specify the configs needed for training
      training_configs:       


        # The batch sizes for training per GPU
        # This will automatically scale the batch size when we scale the number of GPUs
        batch_sizes_per_gpu:
          training: 2
          validation: 2

        # # How many epochs to train for
        # epochs: 5

        # These are the learning rates for the internal models
        # If you want to use 1 learnung rate for all the models you can set "full_model" but then there can be no other entries
        learning_rates:
          forward_output_bandwidth_model:       0.01
          backward_output_bandwidth_model:      0.01
          forward_resampling_bandwidth_model:   "freeze"
          backward_resampling_bandwidth_model:  "freeze"
          output_bandwidth_model:               "freeze"
          forward_dynamics_model:               "freeze"
          backward_dynamics_model:              "freeze"
          forward_output_weights_model:         "freeze"
          backward_output_weights_model:        "freeze"
          forward_resampling_weights_model:     "freeze"
          backward_resampling_weights_model:    "freeze"
          output_weights_model:                 "freeze"
          map_encoder_model:                    "freeze"
          observation_encoder_model:            "freeze"

        models_with_disabled_gradients:
          - observation_encoder_model
          - map_encoder_model
          - forward_resampling_bandwidth_model
          - backward_resampling_bandwidth_model
          - output_bandwidth_model
          - forward_dynamics_model
          - backward_dynamics_model
          - forward_output_weights_model
          - backward_output_weights_model
          - forward_resampling_weights_model
          - backward_resampling_weights_model
          - output_weights_model



  - MDPS_Training_Weights_Template:


      # The parameters for the device to use
      # This specifies which GPU or how many GPUs we want and also what the requirements are for the GPU
      device_configs:
        device: "cuda_use_all"
        min_free_memory_gb: 1.0
        max_number_of_tasks: 10


      # The save dir
      save_dir: <root_save_dir>/004_training_weights/


      # Specify which model to load
      pretrained_models:
        full_model: <root_save_dir>/003_training_filters_stage_3/<framework_var_run_number>/models/best/full_model.pt


      # The config file for the dataset we want to use 
      dataset_configs_file: "../experiments/kitti/shared_configs/dataset_kitti_sequences_long.yaml"

      # Specify the configs needed for training
      training_configs:       


        # The batch sizes for training per GPU
        # This will automatically scale the batch size when we scale the number of GPUs
        batch_sizes_per_gpu:
          training: 2
          validation: 2

        num_cpu_cores_for_dataloader: 8

        # These are the learning rates for the internal models
        # If you want to use 1 learnung rate for all the models you can set "full_model" but then there can be no other entries
        learning_rates:
          forward_output_bandwidth_model:       "freeze"
          backward_output_bandwidth_model:      "freeze"
          forward_resampling_bandwidth_model:   "freeze"
          backward_resampling_bandwidth_model:  "freeze"
          forward_dynamics_model:               "freeze"
          backward_dynamics_model:              "freeze"
          forward_output_weights_model:         "freeze"
          backward_output_weights_model:        "freeze"
          forward_resampling_weights_model:     "freeze"
          backward_resampling_weights_model:    "freeze"
          observation_encoder_model:            "freeze"
          map_encoder_model:                    "freeze"

          output_weights_model:                 0.001
          output_bandwidth_model:               0.0001

        models_with_disabled_gradients:
          - observation_encoder_model
          - map_encoder_model
          - forward_output_bandwidth_model
          - backward_output_bandwidth_model
          - forward_resampling_bandwidth_model
          - backward_resampling_bandwidth_model
          - forward_dynamics_model
          - backward_dynamics_model
          - forward_output_weights_model
          - backward_output_weights_model
          - forward_resampling_weights_model
          - backward_resampling_weights_model

        # The configs for the loss.  At minimum you need to specify the "name". 
        # All additional configs are metric specific
        loss_configs: 
          name: KDENLLMetric
          output_keys:
            particles: "particles"
            particle_weights: "particle_weights"
            bandwidths: "bandwidths"

          particle_extract_dim_params:
            0: 
              dim_in_kde: 0
              kde_distribution_type: "Normal"
            1: 
              dim_in_kde: 1
              kde_distribution_type: "Normal"
            2: 
              dim_in_kde: 2
              kde_distribution_type: "VonMises"




  - MDPS_Training_Bands_Template:


      # The parameters for the device to use
      # This specifies which GPU or how many GPUs we want and also what the requirements are for the GPU
      device_configs:
        device: "cuda_use_all"
        min_free_memory_gb: 1.0
        max_number_of_tasks: 10


      # The save dir
      save_dir: <root_save_dir>/004_5_training_weights/


      # Specify which model to load
      pretrained_models:
        full_model: <root_save_dir>/004_training_weights/<framework_var_run_number>/models/best/full_model.pt


      # The config file for the dataset we want to use 
      dataset_configs_file: "../experiments/kitti/shared_configs/dataset_kitti_sequences_long.yaml"

      # Specify the configs needed for training
      training_configs:       


        # The batch sizes for training per GPU
        # This will automatically scale the batch size when we scale the number of GPUs
        batch_sizes_per_gpu:
          training: 2
          validation: 2

        num_cpu_cores_for_dataloader: 8

        # These are the learning rates for the internal models
        # If you want to use 1 learnung rate for all the models you can set "full_model" but then there can be no other entries
        learning_rates:
          forward_output_bandwidth_model:       "freeze"
          backward_output_bandwidth_model:      "freeze"
          forward_resampling_bandwidth_model:   "freeze"
          backward_resampling_bandwidth_model:  "freeze"
          forward_dynamics_model:               "freeze"
          backward_dynamics_model:              "freeze"
          forward_output_weights_model:         "freeze"
          backward_output_weights_model:        "freeze"
          forward_resampling_weights_model:     "freeze"
          backward_resampling_weights_model:    "freeze"
          observation_encoder_model:            "freeze"
          map_encoder_model:                    "freeze"

          output_weights_model:                 "freeze"
          output_bandwidth_model:               0.01

        models_with_disabled_gradients:
          - observation_encoder_model
          - map_encoder_model
          - forward_output_bandwidth_model
          - backward_output_bandwidth_model
          - forward_resampling_bandwidth_model
          - backward_resampling_bandwidth_model
          - forward_dynamics_model
          - backward_dynamics_model
          - forward_output_weights_model
          - backward_output_weights_model
          - forward_resampling_weights_model
          - backward_resampling_weights_model

        # The configs for the loss.  At minimum you need to specify the "name". 
        # All additional configs are metric specific
        loss_configs: 
          name: KDENLLMetric
          output_keys:
            particles: "particles"
            particle_weights: "particle_weights"
            bandwidths: "bandwidths"

          particle_extract_dim_params:
            0: 
              dim_in_kde: 0
              kde_distribution_type: "Normal"
            1: 
              dim_in_kde: 1
              kde_distribution_type: "Normal"
            2: 
              dim_in_kde: 2
              kde_distribution_type: "VonMises"






  - MDPS_Training_all_Template:

      # The parameters for the device to use
      # This specifies which GPU or how many GPUs we want and also what the requirements are for the GPU
      device_configs:
        device: "cuda_use_all"
        min_free_memory_gb: 1.0
        max_number_of_tasks: 10



      # The save dir
      save_dir: <root_save_dir>/005_training_all/


      # Specify which model to load
      pretrained_models:
        # full_model: <root_save_dir>/004_training_weights/<framework_var_run_number>/models/best/full_model.pt
        full_model: <root_save_dir>/004_5_training_weights/<framework_var_run_number>/models/best/full_model.pt




      # The config file for the dataset we want to use 
      dataset_configs_file: "../experiments/kitti/shared_configs/dataset_kitti_sequences_long.yaml"

      # Specify the configs needed for training
      training_configs:       


        # data_plotter_plot_modulo: 50

        # The batch sizes for training per GPU
        # This will automatically scale the batch size when we scale the number of GPUs
        batch_sizes_per_gpu:
          training: 2
          validation: 2

        num_cpu_cores_for_dataloader: 12

        # These are the learning rates for the internal models
        # If you want to use 1 learnung rate for all the models you can set "full_model" but then there can be no other entries
        learning_rates:
          observation_encoder_model:            "freeze"
          map_encoder_model:                    "freeze"

          forward_output_bandwidth_model:       0.000001
          backward_output_bandwidth_model:      0.000001
          forward_resampling_bandwidth_model:   0.000001
          backward_resampling_bandwidth_model:  0.000001
          forward_dynamics_model:               0.0001
          backward_dynamics_model:              0.0001
          forward_output_weights_model:         0.0001
          backward_output_weights_model:        0.0001
          forward_resampling_weights_model:     0.0001
          backward_resampling_weights_model:    0.0001
          output_weights_model:                 0.0001
          output_bandwidth_model:               0.0001

        models_with_disabled_gradients:
          - observation_encoder_model
          - map_encoder_model

        # The configs for the loss.  At minimum you need to specify the "name". 
        # All additional configs are metric specific
        loss_configs: 
          name: KDENLLMetric
          output_keys:
            particles: "particles"
            particle_weights: "particle_weights"
            bandwidths: "bandwidths"

          particle_extract_dim_params:
            0: 
              dim_in_kde: 0
              kde_distribution_type: "Normal"
            1: 
              dim_in_kde: 1
              kde_distribution_type: "Normal"
            2: 
              dim_in_kde: 2
              kde_distribution_type: "VonMises"





  - MDPS_Evaluation_Template:

      # The parameters for the device to use
      # This specifies which GPU or how many GPUs we want and also what the requirements are for the GPU
      device_configs:
        device: "cuda_auto_multi:1"
        min_free_memory_gb: 1.0
        max_number_of_tasks: 10

      evaluation_configs:         


        # num_cpu_cores_for_dataloader: 16
        num_cpu_cores_for_dataloader: 4


        # The configs for the qualitative phase
        qualitative_config:

          # If we should run the qualitative
          do_run: True 

          save_model_input_output_for_rendering_config:
            do_save: True
            number_to_save: 50

          # The configs for the dynamics model propagation renderings
          # This is the rendering that shows how the dynamics model works
          save_model_input_output_dynamics_model_propagation_config:

            # If we should even render the sequences
            do_save: False

            # How many sequences to render
            number_to_save: 5

            # The name of the model to use as the dynamics model
            dynamics_model_name: "forward_dynamics_model"

            # Get the direction to propagate.
            # This can either be forward or backward
            direction: "forward"

            # The number of samples to draw from the dynamics model to generate the 
            # new position cloud
            number_of_samples: 250






          # The configs for the sequence renderings
          sequence_rendering_config:

            # If we should even render the sequences
            do_render: False

            # How many sequences to render
            number_to_render: 10

            # The Configs for rendering the XY KDE for the sequence rendering
            xy_kde_posterior_rendering_configs:

              # Of we should render the KDE
              do_render: True

              # What dimes to extract for rendering the KDE
              # and the distribution to use when rendering for each dim
              particle_extract_dim_params:
                0: 
                  dim_in_kde: 0
                  kde_distribution_type: "Normal"
                1: 
                  dim_in_kde: 1
                  kde_distribution_type: "Normal"

            # The configs to use while rendering the angle dims KDE
            angle_kde_posterior_rendering_configs:
              
              # If we should even render the KDE
              do_render: True

              # What dimes to extract for rendering the KDE
              # and the distribution to use when rendering for each dim
              particle_extract_dim_params:
                2: 
                  dim_in_kde: 0
                  kde_distribution_type: "VonMises"

          # The configs for the dynamics model propagation renderings
          # This is the rendering that shows how the dynamics model works
          dynamics_model_propagation_rendering_config:

            # If we should even render the sequences
            do_render: False

            # How many sequences to render
            number_to_render: 5

            # The name of the model to use as the dynamics model
            dynamics_model_name: "dynamics_model"

            # Get the direction to propagate.
            # This can either be forward or backward
            direction: "forward"

            # The number of samples to draw from the dynamics model to generate the 
            # new position cloud
            number_of_samples: 25

            # The figure renderings number of rows and columns
            rows: 4
            cols: 5





        quantitative_config:
          do_run: True

          # The batch sizes per GPU
          # This will automatically scale the batch size when we scale the number of GPUs
          batch_sizes_per_gpu:
            evaluation: 2



          metric_configs:

            mdps_nll:
              type: kde_nll
              output_keys:
                particles: "particles"
                particle_weights: "particle_weights"
                bandwidths: "bandwidths"
              particle_extract_dim_params:
                0: 
                  dim_in_kde: 0
                  kde_distribution_type: "Normal"
                1: 
                  dim_in_kde: 1
                  kde_distribution_type: "Normal"
                2: 
                  dim_in_kde: 2
                  kde_distribution_type: "VonMises"

            mdpf_forward_nll:
              type: kde_nll
              output_keys:
                particles: "forward_particles"
                particle_weights: "forward_particle_weights"
                bandwidths: "forward_bandwidths"
              particle_extract_dim_params:
                0: 
                  dim_in_kde: 0
                  kde_distribution_type: "Normal"
                1: 
                  dim_in_kde: 1
                  kde_distribution_type: "Normal"
                2: 
                  dim_in_kde: 2
                  kde_distribution_type: "VonMises"

            mdpf_backward_nll:
              type: kde_nll
              output_keys:
                particles: "backward_particles"
                particle_weights: "backward_particle_weights"
                bandwidths: "backward_bandwidths"

              particle_extract_dim_params:
                0: 
                  dim_in_kde: 0
                  kde_distribution_type: "Normal"
                1: 
                  dim_in_kde: 1
                  kde_distribution_type: "Normal"
                2: 
                  dim_in_kde: 2
                  kde_distribution_type: "VonMises"


            position_recall:
              type: multiple_distance_recall

              # Measure the euclidean distance 
              distance_measurement_type: "Euclidean"

              # The list of metrics that we will be computing
              metrics:




                # MDPS Position
                mdps_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "single_point_prediction"

                # MDPF Forward Position
                forward_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "forward_single_point_prediction"

                # MDPF Backward Position
                backward_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "backward_single_point_prediction"


                # MDPS Top Modes Position
                mdps_top_modes_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "top_modes"


                # MDPS Top Modes Position
                forward_top_modes_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "forward_top_modes"



                # MDPS Top Modes Position
                backward__top_modes_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "backward_top_modes"







                # # MDPS Top Modes Position Refined
                # mdps_top_modes_refined_position_recall:
                #   multiple_hypothesis_selection_mode: "min"
                #   output_keys:
                #     single_point_prediction: "top_modes_refined"


                # # MDPS Top Modes Position Refined
                # forward_top_modes_refined_position_recall:
                #   multiple_hypothesis_selection_mode: "min"
                #   output_keys:
                #     single_point_prediction: "forward_top_modes_refined"



                # # MDPS Top Modes Position Refined
                # backward_top_modes_refined_position_recall:
                #   multiple_hypothesis_selection_mode: "min"
                #   output_keys:
                #     single_point_prediction: "backward_top_modes_refined"








              # Which dims of the single point prediction we want to use
              # For position we just need the first 2 dims
              single_point_prediction_dims_to_use: [0, 1]

              # Which dims of the true state to use
              # For position we just need the first 2 dims
              true_state_dims_to_use: [0, 1]

              # The thresholds to use (in meters)
              thresholds: [0, 0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]





            mdps_angle_recall:
              type: multiple_distance_recall

              # Measure the euclidean distance 
              distance_measurement_type: "Angle"

              # The list of metrics that we will be computing
              metrics:

                # MDPS angle
                mdps_angle_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "single_point_prediction"

                # MDPF Forward angle
                forward_angle_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "forward_single_point_prediction"

                # MDPF Backward angle
                backward_angle_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "backward_single_point_prediction"


                # MDPS Top Modes angle
                mdps_top_modes_angle_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "top_modes"


                # MDPS Top Modes angle
                forward_top_modes_angle_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "forward_top_modes"

                # MDPS Top Modes angle
                backward__top_modes_angle_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "backward_top_modes"


                # # MDPS Top Modes Angle Refined
                # mdps_top_modes_refined_angle_recall:
                #   multiple_hypothesis_selection_mode: "min"
                #   output_keys:
                #     single_point_prediction: "top_modes_refined"


                # # MDPS Top Modes Angle Refined
                # forward_top_modes_refined_angle_recall:
                #   multiple_hypothesis_selection_mode: "min"
                #   output_keys:
                #     single_point_prediction: "forward_top_modes_refined"



                # # MDPS Top Modes Angle Refined
                # backward_top_modes_refined_angle_recall:
                #   multiple_hypothesis_selection_mode: "min"
                #   output_keys:
                #     single_point_prediction: "backward_top_modes_refined"



              # Which dims of the single point prediction we want to use
              # For angle we just want the last dim
              single_point_prediction_dims_to_use: [2]

              # Which dims of the true state to use
              true_state_dims_to_use: [2]

              # The thresholds to use (in radians)
              thresholds: [0, 0.01745329, 0.05235988, 0.08726646, 0.12217305, 0.15707963, 0.19198622, 0.2268928, 0.26179939, 0.29670597, 0.33161256, 0.36651914, 0.40142573, 0.43633231, 0.4712389, 0.50614548, 0.54105207, 0.57595865, 0.61086524, 0.64577182, 0.68067841, 0.71558499, 0.75049158, 0.78539816, 0.82030475, 0.85521133, 0.89011792, 0.9250245, 0.95993109, 0.99483767, 1.02974426, 1.06465084, 1.09955743, 1.13446401, 1.1693706, 1.20427718, 1.23918377, 1.27409035, 1.30899694, 1.34390352, 1.37881011, 1.41371669, 1.44862328, 1.48352986, 1.51843645, 1.55334303]

              # The scale factor to use when displaying if needed
              # this is an optional config. Default value will be 1 if this config is not included
              thresholds_display_scale_factor: 57.2957795131







            position_vehicle_frame_recall:
              type: multiple_distance_recall_xy_vehicle_frame_metric

              # The list of metrics that we will be computing
              metrics:

                # MDPS Position
                mdps_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "single_point_prediction"

                # MDPF Forward Position
                forward_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "forward_single_point_prediction"

                # MDPF Backward Position
                backward_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "backward_single_point_prediction"


                # MDPS Top Modes Position
                mdps_top_modes_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "top_modes"


                # MDPS Top Modes Position
                forward_top_modes_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "forward_top_modes"


                # MDPS Top Modes Position
                backward_top_modes_position_recall:
                  multiple_hypothesis_selection_mode: "min"
                  output_keys:
                    single_point_prediction: "backward_top_modes"


                # # MDPS Top Modes Position Refined
                # mdps_top_modes_refined_position_recall:
                #   multiple_hypothesis_selection_mode: "min"
                #   output_keys:
                #     single_point_prediction: "top_modes_refined"


                # # MDPS Top Modes Position Refined
                # forward_top_modes_refined_position_recall:
                #   multiple_hypothesis_selection_mode: "min"
                #   output_keys:
                #     single_point_prediction: "forward_top_modes_refined"



                # # MDPS Top Modes Position Refined
                # backward__top_modes_refined_position_recall:
                #   multiple_hypothesis_selection_mode: "min"
                #   output_keys:
                #     single_point_prediction: "backward_top_modes_refined"



              # Which dims of the single point prediction we want to use
              # For position we just need the first 2 dims
              single_point_prediction_xy_dim_to_use: [0, 1]

              # The thresholds to use (in meters)
              thresholds: [0, 0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]















